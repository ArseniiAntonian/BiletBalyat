# 1. Алгоритмы и их типы
    Алгоритм - это формально описанная вычислительная процедура, получающая исходные данные и выдающие результат вычисления на выходе. Существует несколько типов алгоритмов, вот некоторые из них:

	   1)Линейный алгоритм - это алгоритм, который выполняет последовательность шагов, идущих один за дргуим, без каких-либо ветвлений или циклов. Он состоит из простой последовательности операций, выполняющихся одна за другой, без принятия решений или повторения шагов.

       2) Ветвящийся алгоритм - это алгоритм, в котором выполнение шагов зависит от выполнения определенного условия. Он включает в себя конструкции ветвления, такие как if-else (если-иначе), switch-case (переключение-случай).

       3) Циклический алгоритм - это алгоритм, в котором набор операций выполняется несколько раз в зависимости от заданного условия. Он включает в себя циклы, такие как цикл while, цикл for, цикл do-while и другие.

# 2.  Требования предъявляемые к алгоритмам
    1) Корректность: алгоритм должен выполнять поставленную перед ним задачу правильно и безошибочно.

    2) Эффективность: алгоритм должен быть эффективным в плане использования ресурсов (времени и памяти). Он должен выполняться за разумное время и использовать минимальное количество памяти.

    3) Масштабируемость: алгоритм должен быть способен работать с различными объемами данных, без потери производительности или точности результата.

    4) Устойчивость: алгоритм должен быть устойчивым к возможным ошибкам входных данных или изменениям в окружающей среде. Он должен продолжать работать корректно даже при наличии непредвиденных ситуаций.

    5) Понятность: алгоритм должен быть понятным и легко читаемым для других программистов. Он должен быть написан с использованием понятных имен переменных, комментариев и структурированного кода.

    6) Портативность: алгоритм должен быть написан таким образом, чтобы его можно было использовать на различных платформах и в различных языках программирования.

    7) Безопасность: алгоритм должен быть безопасным и защищенным от возможных атак или злоумышленников. Он должен предусматривать механизмы защиты данных и проверку на корректность ввода.

    8) Практичность: алгоритм должен быть практичным и применимым для решения реальных задач. Он должен быть достаточно гибким, чтобы можно было адаптировать его под различные ситуации и требования.

# 3. Семейства алгоритмов и их эффективность

1) Прямое решение: эти алгоритмы проверяют все возможные варианты решения задачи. Они гарантированно находят оптимальное решение, но могут быть очень медленными при большом количестве вариантов. Примеры: алгоритм полного перебора, алгоритм ветвей и границ.

2) Жадный подход: эти алгоритмы делают локально оптимальные выборы на каждом шаге, надеясь, что это приведет к глобально оптимальному решению. Жадные алгоритмы обычно работают быстро, но не всегда дают оптимальное решение. Примеры: алгоритм Дейкстры, алгоритм Хаффмана.

3) Разделяй и властвуй: эти алгоритмы разбивают задачу на несколько подзадач, решают каждую подзадачу отдельно, а затем комбинируют результаты. Разделяй и властвуй обычно имеет логарифмическую сложность, но может потребовать большого объема памяти. Примеры: алгоритм быстрого возведения в степень, алгоритм сортировки слиянием.   

4) Параллельные алгоритмы - разрабатываются для распараллеливания выполнения задач, позволяя множеству вычислительных устройств (процессоров, ядер, узлов сети) работать над общей задачей параллельно.

5) Приближенный алгоритм -  в отличие от точных алгоритмов, приближенные алгоритмы стремятся найти решение, которое может быть не оптимальным, но при этом достаточно близким к оптимальному. Часто приближенные алгоритмы более эффективны с точки зрения вычислительных ресурсов, чем точные алгоритмы, особенно в случаях, когда поиск точного решения требует слишком много времени.
# 4. Демонстрация правильности и неправильности алгоритмов

**Демонстрация правильности

 1) Математическое доказательство: Используется для алгоритмов, основанных на математических принципах. Для этого доказательства используются индукция, протяжение и другие методы математической логики.

 2) Тестирование: Создание тестовых случаев (тест-кейсов), которые покрывают различные аспекты работы алгоритма. Для этого можно использовать библиотеки и фреймворки для тестирования, такие как JUnit (для Java), pytest (для Python) и другие.

 3) Формальные методы: Например, использование специализированных языков проверки моделей, таких как TLA+ и Alloy, которые позволяют формально проверить алгоритм на соответствие заданным свойствам.

**Демонстрация неправильности: 

   1) Приведение контрпримеров: Поиск входных данных, на которых алгоритм работает неправильно. Это может быть сделано путем ручного анализа или автоматизированными методами, такими как символьное выполнение.

   2) Доказательство неправильности: Использование методов математической логики для доказательства того, что алгоритм работает неправильно в определенных случаях.

   3) Отладка и анализ: Использование средств отладки (например, отладчика в среде разработки) для выявления ошибок внутри алгоритма и анализа его работы

# 5. Индукция и рекурсия

### Индукция:

   Индукция - это математический метод доказательства утверждений. Метод индукции часто используется для доказательства истинности утверждений для всех натуральных чисел. Он строится на принципе математической индукции, который состоит из трех шагов:

   1. База индукции: Доказательство того, что утверждение верно для начального значения (обычно для n=1 или n=0).

   2. Шаг индукции: Доказательство, что если утверждение верно для некоторого числа k, то оно также верно и для числа k+1.

   3. Заключение: На основании базы и шага индукции делается вывод, что утверждение верно для всех натуральных чисел.

### Рекурсия:

 Рекурсия - это техника в программировании, когда функция вызывает саму себя. Рекурсивные функции используются в различных алгоритмах, таких как обход деревьев, сортировка, вычисление факториала и многих других. Чтобы рекурсивная функция завершила работу, она должна содержать базовый случай, который представляет собой условие выхода из "рекурсивного спуска", в противном случае это может привести к бесконечному циклу.

### Рекурсия и индукция:

   В контексте рекурсивных функций индукция играет важную роль. Утверждения, связанные с рекурсивной функцией, часто можно доказать методом математической индукции. Таким образом, индукция может использоваться для доказательства корректности работы рекурсивной функции.

   Рекурсия также тесно связана с понятием индукции в дискретной математике. Метод математической индукции часто используется для доказательства свойств рекурсивных алгоритмов и структур данных.

Таким образом, индукция и рекурсия имеют глубокое взаимодействие как в математике, так и в программировании, и оба этих концепции играют важную роль в доказательстве корректности программ и алгоритмов.

# 6. Комбинаторные и рекурсивные объекты при моделировании

Комбинаторика - это раздел математики, который занимается подсчетом, упорядочиванием и комбинированием различных элементов в конечные структуры. В программировании комбинаторика часто используется для решения задач, связанных с перестановками, сочетаниями, размещениями элементов и другими комбинаторными задачами.

Вот несколько примеров, когда комбинаторика применяется в программировании:
    - Решение задач на перебор всех возможных комбинаций элементов (например, в задачах о перестановках или сочетаниях).
    - Работа с алгоритмами оптимизации, такими как генетические алгоритмы или метаэвристики, которые используют комбинаторные приемы.

Рекурсивные структуры данных также играют важную роль в программировании. Рекурсия - это техника, при которой функция вызывает саму себя в своем определении. Рекурсивные структуры данных часто используются для многих целей, включая обход деревьев, моделирование иерархических структур, решение задач, связанных с комбинаторикой, и многие другие. 

Примерами рекурсивных структур данных могут быть:
    - Древовидные структуры, такие как бинарные деревья или деревья решений, которые часто моделируются рекурсивно.
    - Списки или цепочки структур, которые могут быть определены рекурсивно (например, список как голова и хвост, где хвост также может быть списком).

Использование комбинаторики и рекурсивных структур данных в программировании позволяет решать множество сложных задач, создавать эффективные алгоритмы, а также моделировать сложные системы. Эти концепции расширяют возможности создания программ и часто используются при решении различных задач.

# 7. Модели вычислений

Модели вычислений представляют собой абстрактные концепции, которые описывают способы, с помощью которых происходит вычисление в программировании. 
1) RAM
	- Для исполнения любой простой операции требуется ровно один временной шаг
	- Циклы и подпрограммы не считаются простыми операциями, а состоят из нескольких простых операций
	- Каждое обращение к памяти занимает один временной шаг
	- Компьютер обладает неограниченным объемом оперативной памяти
2) Модель конвейера
	- Деление на этапы: Конвейерная модель делит весь процесс обработки инструкций на несколько последовательных этапов (например, извлечение инструкции, декодирование, выполнение, запись результата).
	-  Параллельное выполнение: В конвейерной модели каждый этап обработки работает параллельно, что позволяет обрабатывать несколько инструкций одновременно.
	- Эффективное использование аппаратуры: Исполнение нескольких инструкций одновременно и перекрытие обработки различных инструкций позволяет использовать вычислительные ресурсы более эффективно.
3) Параллельная модель
	- позволяет выполнять несколько задач (или подзадач) одновременно, ускоряя общее время выполнения программы.
	-   Модель потоков выполнения, в рамках параллельных вычислений, позволяет различным частям программы работать независимо и одновременно. Это может быть реализовано через многопоточность или многопроцессорность.
	- Параллельные вычисления также могут включать распределенные вычисления, где задачи выполняются на различных вычислительных узлах, обычно связанных сетью. Это открывает возможности для эффективного использования ресурсов в масштабе сети или облака.

# 8.  Анализ сложности алгоритма. Наилучший, наихудший и средний случаи.

Анализ сложности алгоритма важен для оценки того, как его производительность будет изменяться с увеличением размера входных данных. При рассмотрении сложности алгоритма обычно выделяют три ключевых случая: наилучший, наихудший и средний. Позвольте мне подробнее объяснить каждый из них.

1) Наилучший случай сложности (Best-Case Complexity): Это оценка времени выполнения алгоритма при наилучших возможных входных данных. Наилучший случай сложности представляет собой ситуацию, когда алгоритм работает наиболее эффективно или достигает минимальной временной сложности. Например, для алгоритмов сортировки этот случай может наступить, когда массив уже отсортирован.
2) Наихудший случай сложности (Worst-Case Complexity): Это оценка времени выполнения алгоритма при наихудших входных данных. Наихудший случай сложности представляет ситуацию, когда алгоритм работает наиболее неэффективно или достигает максимальной временной сложности. Для алгоритмов сортировки наихудший случай может быть, когда массив отсортирован в обратном порядке.
3) Средний случай сложности (Average-Case Complexity): Это оценка времени выполнения алгоритма при средних входных данных. Средний случай сложности представляет ситуацию, когда алгоритм работает в среднем по всевозможным входным данным. Это может потребовать проведения статистического анализа или вычисления математических ожиданий.

Анализ сложности в различных случаях важен для полного понимания производительности алгоритма на практике. Часто бывает так, что наихудший случай сложности является наиболее критическим для оценки общей производительности алгоритма, поскольку он представляет верхнюю границу временной сложности.

# 9. Классификация алгоритмов по виду функции трудоемкости

1. Количественно-зависимые по трудоемкости алгоритмы 
2. Параметрически-зависимые по трудоемкости алгоритмы 
3. Количественно-параметрические по трудоемкости алгоритмы
	 - порядково зависимые по трудоемкости
# 10.  Асимптотические обозначения и асимптотический анализ

1. . **O-большое (Big O)**: Обозначает оценку сверху трудоемкости алгоритма. Формально, функция f(n) принадлежит классу O(g(n)), если существуют положительные постоянные M и n₀ такие, что f(n) <= M * g(n) для всех n > n₀.
2. **Ω-большое (Big Omega)**: Обозначает оценку снизу трудоемкости алгоритма. Функция f(n) принадлежит классу Ω(g(n)), если существуют положительные постоянные M и n₀ такие, что f(n) >= M * g(n) для всех n > n₀.
2. **Θ-большое (Big Theta): Обозначает точную оценку трудоемкости алгоритма. Функция f(n) принадлежит классу Θ(g(n)), если она принадлежит одновременно классам O(g(n)) и Ω(g(n))

Анализ сложности в различных случаях важен для полного понимания производительности алгоритма на практике. Часто бывает так, что наихудший случай сложности является наиболее критическим для оценки общей производительности алгоритма, поскольку он представляет верхнюю границу временной сложности.

# 11.  Скорость роста и отношения доминирования. Семейства производительности
#### Семейства производительности

1. Константное время (O(1)): Такие алгоритмы имеют постоянное время выполнения, независимо от размера входных данных.
  
2. Логарифмическое время (O(log n)): Алгоритмы с логарифмическим временем роста увеличиваются логарифмически по отношению к размеру входных данных. Пример: бинарный поиск.

3. Линейное время (O(n)): Время выполнения линейного алгоритма линейно зависит от размера входных данных.

4. Линейно-логарифмическое время (O(n log n)): Это типично для многих эффективных алгоритмов сортировки, таких как QuickSort и MergeSort.

5. Квадратичное время (O(n^2)): Алгоритмы с квадратичным временем выполнения увеличиваются квадратично по отношению к размеру входных данных. Пример: сортировка вставками.

6. Экспоненциальное время (O(2^n)): Алгоритмы с экспоненциальным временем роста растут экспоненциально по отношению к размеру входных данных.
#### Отношения доминирования

В анализе скорости роста алгоритмов отношения доминирования или "Big O" (O-нотация) используются для определения верхней границы роста времени выполнения алгоритма при увеличении размера входных данных.
![[Pasted image 20240113225448.png]]

#### Применение в программировании

Основное понимание скорости роста и отношений доминирования является ключевым для выбора подходящих алгоритмов при решении конкретных задач. Например, при работе с большими объемами данных важно выбирать алгоритмы с более низкой скоростью роста, чтобы обеспечить эффективное выполнение программы.
Также эта тема важна в контексте оценки производительности и масштабируемости программных систем. Понимание скорости роста и оценка времени выполнения алгоритмов помогает разработчикам выбирать оптимальные методы и структуры данных, что в конечном итоге влияет на работу и производительность программы.

#### Семейства производительности

В программировании семейства производительности относятся к набору функций, методов, классов или структур данных, предоставляемых в рамках стандартной библиотеки или фреймворка, которые решают сходные задачи, но могут иметь различную производительность или свойства в различных сценариях использования. Давай распишем некоторые из семейств производительности:

#### Семейства алгоритмов сортировки

Различные алгоритмы сортировки (например, быстрая сортировка, сортировка слиянием, сортировка пузырьком, сортировка вставками) предоставляют разные профили производительности и могут быть применены на практике в зависимости от объема данных, типа данных, требований по памяти и других факторов.

#### Контейнеры данных


В стандартных библиотеках языков программирования, таких как C++, Java, Python, существует множество контейнеров данных (например, списки, массивы, карты/словари, множества). Каждый из них обладает уникальными характеристиками производительности в зависимости от операций, которые необходимо выполнять (вставка, поиск, удаление и т.д.).

#### Семейства алгоритмов поиска

В компьютерных науках существует несколько алгоритмов поиска, каждый из которых имеет свои уникальные характеристики производительности. Например, бинарный поиск, поиск по hash-таблице, линейный поиск и другие.

#### Семейства структур данных

Структуры данных, такие как списки, деревья (BST, AVL, красно-черные деревья), хеш-таблицы, кучи и другие, могут быть рассмотрены как семейства производительности, так как они предоставляют разные компромиссы между доступом, вставкой, удалением и другими операциями.

#### Применение в программировании

Изучение и понимание семейств производительности важно для выбора оптимальных решений и ресурсов при проектировании и разработке программного обеспечения. Знание различных алгоритмов, структур данных или методов позволяет разработчику выбирать наиболее подходящие для конкретной задачи, обеспечивая оптимальную производительность.

Кроме того, семейства производительности также помогают программистам принимать решения о том, как использовать различные компоненты стандартной библиотеки или фреймворка в зависимости от требований по производительности, ограничений по памяти и других факторов.


# 12. Логарифмы и иx применение

Логарифмы - это важный математический инструмент, который находит множество применений в программировании. Давайте рассмотрим некоторые из основных областей, в которых логарифмы используются в программировании:

1. Анализ алгоритмов: Логарифмическая сложность часто встречается в алгоритмах. Например, в алгоритмах сортировки, таких как быстрая сортировка или сортировка слиянием, время выполнения зависит от логарифма от размера данных. Использование логарифмической сложности позволяет создавать эффективные алгоритмы для обработки больших объемов данных.
2. Бинарный поиск: Одним из классических примеров использования логарифмов является бинарный поиск. Если массив отсортирован, бинарный поиск позволяет быстро найти элемент за время, пропорциональное логарифму от размера массива.
3. Структуры данных: Логарифмически сложные структуры данных, такие как сбалансированные двоичные деревья (например, красно-черные деревья), широко используются в программировании. Они обеспечивают быстрый доступ и вставку данных за счет логарифмической сложности операций.
4. Хэш-таблицы: Время доступа к элементам в хэш-таблицах часто оценивается с использованием логарифмической сложности. Это связано с тем, что при правильном выборе хэш-функции, время доступа остается логарифмическим относительно общего количества элементов в таблице.
5. Алгоритмы ускорения: В различных алгоритмах ускорения, таких как алгоритмы поиска ближайших точек или алгоритмы быстрого преобразования Фурье (FFT), логарифмическая сложность играет важную роль в определении производительности алгоритмов.
Логарифмы предоставляют нам мощный инструмент в программировании для создания эффективных алгоритмов, структур данных и операций, что позволяет эффективно обрабатывать большие объемы данных и оптимизировать производительность программ.

# 13. Теория сложности вычислений и сложностные классы задач

Теория сложности вычислений - это раздел теоретической информатики, который изучает ресурсы, необходимые для решения задач, и классифицирует задачи по степени вычислительной сложности. Понимание сложности вычислений помогает программистам понять, насколько эффективно и масштабируемо их программы, и выбрать подходящие алгоритмы для решения конкретных задач.

Вот несколько основных сложностных классов задач в программировании:

 1. P-класс задач: Этот класс включает задачи, для которых существует алгоритм, который может быть выполнен за полиномиальное время от размера входных данных. В основе P-класса лежит идея, что задачи в этом классе могут быть эффективно решены при помощи классических компьютеров за разумное время.
 2. NP-класс задач: Этот класс включает задачи, для которых существует алгоритм, который может быть проверен за полиномиальное время, но нет известных алгоритмов для их решения за полиномиальное время. Примером может служить задача о коммивояжере.
 3. NP-сложные задачи: Этот класс включает задачи, для которых, если существует алгоритм для их решения за полиномиальное время, то существует алгоритм для решения всех задач из класса NP за полиномиальное время. Многие оптимизационные задачи относятся к классу NP-сложных задач.
 4. NP-полные задачи (NPC): Этот класс включает самые трудоемкие задачи из класса NP. Если для любой задачи из класса NP-полного можно построить алгоритм, решающий ее за полиномиальное время, то это будет означать, что P=NP. Примеры NP-полных задач включают задачу о рюкзаке и различные комбинаторные задачи.

Понимание сложностных классов задач важно для разработки эффективных алгоритмов и оптимизации производительности программ. Оно также связано с вопросами теоретической информатики, булевой алгебры, вероятности и комбинаторики, и его применение простирается на различные области, от разработки алгоритмов до криптографии и логистики.

# 14. Строительные блоки алгоритмов. Типы и структуры данных. Абстрактные типы данных

В программировании существует множество "строительных блоков", которые используются для создания алгоритмов. Они включают в себя различные типы и структуры данных, абстрактные типы данных (АТД) и множество других инструментов.

Типы данных:
	- Примитивные типы данных: Например, целые числа, вещественные числа, символы, булевы значения и другие, используются для хранения и обработки простых значений.
	- Строки и массивы: Используются для представления коллекций элементов. Строки представляют текстовые данные, а массивы - упорядоченные наборы элементов одного типа.
	- Указатели и ссылки: Расширяют возможности работы с памятью и динамическими структурами данных.
	- Составные типы данных: Например, записи (structs) и классы (classes/objects), позволяют создавать новые типы данных, состоящие из комбинации других типов данных.

Структуры данных:
	- Списки: Связанные списки, массивы, списки переменной длины. Они представляют упорядоченные коллекции данных.
	- Деревья: Бинарные деревья, деревья поиска, красно-черные деревья. Используются для представления иерархических данных и реализации поиска и сортировки.
	- Хэш-таблицы: Используются для эффективного поиска и индексации данных.
	- Графы: Направленные и ненаправленные графы, используются для представления взаимосвязей между данными.

Абстрактные типы данных (АТД):
	- Стеки (Stacks): Представляют собой упорядоченную коллекцию элементов, к которой можно получить доступ только к последнему добавленному элементу.
	- Очереди (Queues): Представляют упорядоченную коллекцию элементов, в которой элементы добавляются в конец, а удаляются из начала.
	- Множества (Sets): Коллекция уникальных элементов без порядка.
	- Словари (Dictionaries): Связывают ключи с значениями.

Кроме того, абстрактные типы данных (Abstract Data Types - ADT) предоставляют интерфейс для конкретных структур данных, разделяя их реализацию и использование. Например, очередь может быть реализована как массив или как связанный список, но разработчик, использующий ADT для очереди, не обязательно должен знать, какой конкретно способ реализации используется.

Понимание этих "строительных блоков" алгоритмов, типов данных, структур данных и абстрактных типов данных, поможет вам эффективно применять их при разработке программ, выборе алгоритмов и создании эффективных структур для обработки данных.

# 15. Смежные и связанные типы данных. Массивы. Связанные списки

Смежные и связанные типы данных - это два основных типа структур данных, которые используются в программировании.

1. Смежные (Contiguous) типы данных:
	   - Массивы (Arrays): Это одна из основных форм смежных типов данных. Массив представляет собой упорядоченную коллекцию элементов фиксированного размера. Массивы обеспечивают простой и эффективный способ доступа к элементам по индексу. Однако их размер определяется заранее, что ограничивает их использование в случаях, когда требуется динамическое управление памятью.

2. Связанные (Linked) типы данных:
	   - Связанные списки (Linked Lists): Связанный список представляет собой структуру данных, состоящую из узлов, где каждый узел содержит значение и указатель на следующий узел в последовательности. Связанные списки предоставляют гибкость по сравнению с массивами, поскольку их размер может быть динамически изменен путем добавления или удаления узлов.

Массивы:
	Массивы представляют собой набор элементов одного типа, размещенных в памяти в последовательной, смежной последовательности. Они имеют фиксированную длину, которая определяется на этапе создания. Это делает их эффективными для доступа к элементам по индексу и для хранения упорядоченной коллекции данных. На одном уровне массивы можно рассматривать как прямую реализацию понятия смежной структуры данных.

Связанные списки:
	Связанный список состоит из узлов, каждый из которых содержит данные и ссылку (или указатель) на следующий узел. Это позволяет связанным спискам быть гибкими и динамически растущими структурами данных, в отличие от массивов. Однако, связанный список обычно требует больше памяти из-за накладных расходов на хранение указателей/ссылок.

Оба массивы и связанные списки имеют свои преимущества и недостатки, и выбор одного для конкретной задачи зависит от требований к быстродействию, доступу, изменяемости и структуре данных.

# 16. Проблемы вычислительной реализации алгоритмов

Вычислительная реализация алгоритмов может столкнуться с рядом проблем, включая, но не ограничиваясь следующими:

### 1. Эффективность ресурсов

#### Проблема:
Некоторые алгоритмы потребляют слишком много оперативной памяти, процессорного времени или других ресурсов, делая их менее подходящими для использования в ресурсно ограниченной среде.
### 2. Сложность алгоритма

#### Проблема:
Некоторые алгоритмы имеют высокую вычислительную сложность, что может привести к длительному времени выполнения, особенно при работе с большими объемами данных.
### 3. Недостаточная точность и устойчивость

#### Проблема:
Некоторые алгоритмы могут оказаться недостаточно точными или устойчивыми при работе с особенными типами данных или в непредвиденных сценариях.
### 4. Сложность реализации

#### Проблема:
Некоторые алгоритмы являются сложными для реализации, требуя сложной логики или множества дополнительных шагов.

#### Решение:
Фокус на ясности и модульности кода, использование существующих библиотек и фреймворков, а также тестирование для обеспечения корректной работы.

### 5. Особенности архитектуры и языка программирования

#### Проблема:
Некоторые алгоритмы могут быть подвержены особенностям конкретной архитектуры или языка программирования, что может затруднить их реализацию.

#### Решение:
Изучение особенностей конкретной среды, разработка универсальных и масштабируемых решений, учитывающих различия в различных контекстах.

# 17. Аналитические и численные алгоритмы. Сравнительный анализ

Аналитические и численные алгоритмы представляют два основных подхода к решению математических задач. Давай проведем сравнительный анализ этих двух типов алгоритмов.

### Аналитические алгоритмы

1. Определение: Аналитические алгоритмы используют аналитическое решение, математические формулы и выражения для получения точного решения задачи.
  
2. Применение: Хорошо подходят для задач с аналитический решаемыми моделями, такими как вычисления интегралов, дифференциальных уравнений и аналитических геометрических задач.

3. Точность: Предоставляют аналитически точные решения без необходимости численных приближений.

4. Сложность реализации: Некоторые задачи могут требовать сложных математических решений и могут быть сложными для реализации в виде программ.
### Численные алгоритмы

1. Определение: Численные алгоритмы решают математические задачи путем численного приближения решения.

2. Применение: Они находят широкое применение в задачах, для которых отсутствуют аналитические решения, или когда аналитические решения слишком сложны для практической реализации.

3. Точность: Численные методы дают численные приближенные решения, и точность зависит от используемых методов и их параметров.

4. Сложность реализации: Численные алгоритмы обычно легче реализовывать и могут быть более гибкими при работе с различными видами задач.

### Сравнительный анализ
- Аналитические алгоритмы предоставляют точные аналитические решения.
- Численные алгоритмы предоставляют численные приближенные решения с разной степенью точности.

#### Применение:
- Аналитические алгоритмы хорошо подходят для задач с аналитически решаемыми моделями.
- Численные алгоритмы широко применяются для задач, в которых нет аналитических решений или когда они неэффективны.

#### Сложность реализации:
- Аналитические алгоритмы могут быть сложны для реализации в виде программ в случае сложных математических решений.
- Численные алгоритмы часто более просты в реализации и могут предоставлять более удобные вычислительные решения.

# 18. Деление полиномов. Ряд и теорема Штурма

### Деление полиномов

Выполнение деления полиномов аналогично делению чисел. Пусть у нас есть два полинома: делимое полином P(x) и делитель Q(x). Деление полиномов приводит к получению частного полинома D(x) и остатка R(x). Формально это записывается как:

P(x) = Q(x) · D(x) + R(x), где D(x) - это частное, а R(x) - остаток.

### Ряд и теорема Штурма

Ряд Штурма - это ряд, построенный на основе деления многочлена на его производную. Этот метод может использоваться для нахождения корней многочлена в заданном интервале. Теорема Штурма утверждает, что унитарный многочлен (т.е. многочлен с коэффициентом при старшем члене, равным 1) над полем действительных чисел имеет не более чем одну вещественную положительную корень между каждой парой соседних корней ряда Штурма.

Основные шаги алгоритма, используемого для ряда Штурма:

1. Находим ряд Штурма, вычисляя последовательно частное и остаток от деления многочлена на его производную.
2. Считаем изменение знака в ряде Штурма в заданной точке.
3. Используем результат для определения числа вещественных корней многочлена в данном интервале.
https://youtu.be/8SxRRMbkf4Y

# 19. Численные алгоритмы нахождения корней уравнений. Метод Ньютона и деления пополам

### Метод Ньютона 
http://vmath.ru/vf5/polynomial/newton

### Метод деления отрезка пополам

Метод деления отрезка пополам (или метод бисекции) использует простой итерационный процесс для приближенного нахождения корня уравнения. Начав с двух точек, задающих отрезок, содержащий корень, алгоритм находит середину отрезка и оценивает значение функции в этой точке. Затем корень должен находиться в одной из половин этого отрезка, и процесс продолжается до тех пор, пока не будет достигнута желаемая точность.
# 20. Алгоритм Евклида

и так знаем
# 21. Алгоритм схемы Горнера

и так знаем
# 22. Алгоритм Карацубы

Исходная идея алгоритма Карацубы основана на разложении умножения больших чисел на части и их последующем объединении. Алгоритм использует формулу:

X · Y = 10^n · AC + 10^(n/2)· (AD + BC) + BD

где X и Y - умножаемые числа, A и B - верхние и нижние n/2 знаков, C и D - верхние и нижние n/2 знаков Y. При правильной реализации этот метод значительно уменьшает количество умножений по сравнению со стандартным алгоритмом умножения.
https://youtu.be/JCbZayFr9RE?si=hy1u561lX-fESY4s
# 23. Задача сортировки. Базовые понятия. Сравнимость элементов

Задача сортировки - перестановка элементов оригинальной последовательности для удовлетворения некоторому условию.
Для любых элементов p и q должен выполняться ровно один из трех предикатов:
- p < q
- p > q
- p = q

Сортировка - базовый блок в решении других задач:
- **Поиск - если данные отсортированы, то поиск двоичный, время O(logn) 
- **Поиск ближайшей пары
- **Определение уникальности элементов
- **Частотное распределение - поиск самого часто встречающегося элемента

# 24. Практические аспекты сортировки. Устойчивость. Методы сортировки

### Практические аспекты
1. Эффективность: Важно выбирать оптимальный метод сортировки в зависимости от объема и типа данных. Эффективный выбор метода сортировки может существенно повлиять на производительность программы.

2. Реальное время работы: При использовании сортировки в реальных приложениях, особенно при работе с большими объемами данных, важно знать время работы конкретных методов сортировки и их производительность в конкретной среде.

3. Устойчивость: Важно понимать, как устойчивость сортировки может повлиять на результат при работе с данными, где относительный порядок элементов имеет значение.

4. Сравнение методов: Понимание различных методов сортировки и их применение в разных ситуациях помогает выбирать оптимальный алгоритм для конкретной задачи.

Говорят, что метод сортировки **устойчив**, если он сохраняет относительный порядок размещения элементов в файле, который содержит дублированные ключи.

### Методы сортировки

- Внутренние - если сортируемый файл полностью помещается в оперативке.
- Внешние - если сортируемый файл находится на внешнем носителе. В этом случае возможен только последовательный метод доступа, или по крайней мере доступ к блокам больших размеров

# 25. Факторы, влияющие на выбор сортировки

- Время выполнения
- Дополнительный объем используемой памяти
- Сложность алгоритма
- Объем кода
- Производительность в разных случаях
- Особенности сортируемого набора
# 26. Пирамидальная сортировка

#### 1. Построение кучи
   - Начинаем с построения кучи из массива. Это делается путем перемещения элементов в нужные позиции снизу вверх.
   - Если родительский узел хранится в индексе i, левый дочерний элемент может быть вычислен как 2i+ 1, а правый дочерний элемент — как 2i + 2 (при условии, что индексирование начинается с 0).

#### 2. Сортировка
   - После построения кучи мы извлекаем наибольший элемент из корня кучи (или наименьший, в зависимости от типа сортировки) и уменьшаем размер кучи на 1.
   - Затем мы восстанавливаем свойство пирамиды для оставшихся элементов, что позволяет нам получать наибольший (или наименьший) элемент на каждом шаге.
   - извлеченный элемент пихаем в конец массива
#### Достоинства
› Имеет доказанную оценку худшего случая O(n ⋅ log n).
› Сортирует на месте, то есть требуется всего O(1) дополнительной памяти
#### Недостатки
- ›  Неустойчив.
- ›  Нет разницы в почти отсортированном или хаотичном массиве
- ›  На одном шаге выборку приходится делать хаотично по всей длине массива — поэтому алгоритм плохо сочетается с кэшированием и подкачкой памяти
- ›  Методу требуется «мгновенный» прямой доступ; не работает на связанных списках и других структурах памяти последовательного доступа.
- ›  Не распараллеливается
   https://youtu.be/dzYwcpsKVMk?si=ouaSHIMeUyCmjf11

# 27. Сортировка выбором

- находим мин элемент и суем его в начало
- дальше делаем то же самое с оставшимся массивом

`template <typename type_arr>`
`void selection_sort(type_arr *arr, int size)`
`{`
    `for (int i = 0; i < size - 1; i++)`
    `{`
        `int min_index = i;`
        `for (int j = i + 1; j < size; j++)`
        `{`
            `if (arr[j] < arr[min_index])`
            `{`
                `min_index = j;`
            `}`
        `}`
        `if (min_index != i)`
        `{`
            `swap(arr[i], arr[min_index]);`
        `}`
    `}`
`}`
#### ?????? вопросы ?????
1. Трудоемкость – N2/2 – операций сравнения, N – операций обмена элементов местами
2. Модификация – минимум/максимум
3. Устойчивость – м.б. любым
4. Затраты памяти – нет дополнительных затрат
5. Для каких массивов – не чувствительна к природе входных данных
# 28. Сортировка вставками

- Чтобы отсортировать массив размером N в порядке возрастания, выполните итерацию по массиву и сравните текущий элемент (ключ) с его предшественником, если ключевой элемент меньше своего предшественника, сравните его с предыдущими элементами. Переместите большие элементы на одну позицию вверх, чтобы освободить место для заменяемого элемента.
- ![[Pasted image 20240113161900.png]]
#### ?????? вопросы ?????

1. Трудоемкость – N2/4 – операций сравнения, N2/4 – операций полуобмена элементов местами
(перемещений) и в два раза больше операций в наихудшем случае
2. Модификация – использование бинарного поиска
3. Устойчивость – да
4. Затраты памяти – нет дополнительных затрат
5. Для каких массивов – хороша для частично отсортированного массива

# 29. Пузырьковая сортировка

- Здесь нужно последовательно сравнивать значения соседних элементов и менять числа местами, если предыдущее оказывается больше последующего. Таким образом элементы с большими значениями оказываются в конце списка, а с меньшими остаются в начале.
#### ?????? вопросы ?????

1. Трудоемкость – N2/2 – операций сравнения, N2/2 – операций обмена как в среднем, так и в наихудшем случаях

2. Модификация – шейкерная, чет-нечетная, расческа

3. Устойчивость – да

4. Затраты памяти – нет дополнительных затрат

5. Для каких массивов – хороша для частично отсортированного массива
# 30. Шейкерная сортировка

- Шейкерная сортировка отличается от пузырьковой тем, что она двунаправленная: алгоритм перемещается не строго слева направо, а сначала слева направо, затем справа налево.

`void ShakerSort(vector<int>& values) {`
  `if (values.empty()) {`
    `return;`
  `}`
  `int left = 0;`
  `int right = values.size() - 1;`
  `while (left <= right) {`
    `for (int i = right; i > left; --i) {`
      `if (values[i - 1] > values[i]) {`
        `swap(values[i - 1], values[i]);`
      `}`
    `}`
    `++left;`
    `for (int i = left; i < right; ++i) {`
      `if (values[i] > values[i + 1]) {`
        `swap(values[i], values[i + 1]);`
      `}`
    `}`
    `--right;`
  `}`
`}`

# 31. Чет-нечетная сортировка

модификация пузырьковой сортировки, при которой мы проходимся по четным и нечетным элементам массива

`for(int i = 0; i < a.size(); i++){`  
    `for(int j = (i%2) ? 0: 1; j < a.size() - 1; j += 2){`  
        `if(a[j] > a[j+1]) swap(a[j],a[j+1]);`  
    `}`  
`}`

![[Odd_even_sort_animation.gif]]
#### ?????? вопросы ?????

1. Трудоемкость – O(N2) – наихудшая сложность, O(N log N) – средняя сложность, O(N) – наилучший вариант

2. Модификация – параллельная реализация
    
3. Устойчивость – да
    
4. Затраты памяти – нет дополнительных затрат
    
5. Для каких массивов – хороша для частично отсортированного массива
# 32. Сортировка расческой

- На первом шаге мы находим длину массива (например, 10 элементов) и делим её на 1,247. После округления у нас получилось число 8. Теперь мы проходим первый цикл пузырьковой сортировки, только сравнивая не 1 и 2, 2 и 3, а сразу 1 и 8, 2 и 9, 3 и 10. Это отправит самые большие числа, если они есть в начале, в самый конец. Всего на первом шаге будет три сравнения.

- На втором шаге мы берём число 8 из предыдущего этапа и снова делим его на 1,247, получая число 6. Теперь мы снова проходим весь массив и сравниваем так: 1 и 6, 2 и 7, 3 и 8, 4 и 9, 5 и 10. Уже получилось 5 перестановок и снова крупные числа улетели поближе к концу массива.

- Так мы уменьшаем размер шага до тех пор, пока он не станет меньше единицы — к этому моменту массив будет полностью отсортирован.

`double factor = 1.2473309; // фактор уменьшения`
	`int step = data.size() - 1; // шаг сортировки`
    
    `//Последняя итерация цикла, когда step==1 эквивалентна одному проходу сортировки пузырьком`
	`while (step >= 1)`
	`{`
		`for (int i = 0; i + step < data.size(); i++)`
		`{`
			`if (data[i] > data[i + step])`
			`{`
				`std::swap(data[i], data[i + step]);`
			`}`
		`}`
		`step /= factor;`
	`}`
#### ?????? вопросы ?????

1. Трудоемкость – O(N2) – наихудшее время, O(N) – лучшее время, Ω(N2/2p) – среднее время

2. Модификация – параллельная реализация
    
3. Устойчивость – да
    
4. Затраты памяти – нет дополнительных затрат
    
5. Для каких массивов – ????
# 33. Сортировка Шелла

Сортировка Шелла - обобщенная версия алгоритма сортировки вставками.
-  Сначала сортируем элементы, которые находятся далеко друг от друга, последовательно уменьшаем интервал между элементами, подлежащими сортировке.
-  Расстояние между элементами уменьшается в зависимости от используемой последовательности.
-  Последовательность, предложенная Дональдом Шеллом:  N/2, N/4, . . . , 1.
#### Алгоритм:
- Рассматриваем смещения на каждом шагу (выберем последовательность Шелла, для наглядности): hk = N/2, hk−1 = hk /2, . . . , h0 = 1. На каждом проходе сортируем элементы, которые находятся на расстоянии hk друг от друга. На последнем шагу h0 запускается обычная сортировка вставками. Т.е. выполняется следующая последовательность действий: 
	1. Разбиваем массив на списки, элементы внутри которых отстают друг от друга на hi , кол-во таких списков равно hi .
	2. Внутри каждого такого списка элементы сортируются сортировкой вставками 
	3. Соединяем списки обратно в массив, переходим к шагу i = i − 1.

#### ?????вопросы?????
- последовательность шагов Шелла 1 2 4 8 16 32 64 128 256 512 1024 2048 - O(n^2)
- Последовательность Хиббарда (2k-1) – O(n^3/2)
	1 3 7 15 31 63 127 255 511 1023 ....
- Последовательность Седжвика – O(n^4/3)
	1 5 19 41 109 209 505 929 2161 3905 ....
- Последовательность Пратта (2i 3j) – O(n log^2 n)
	1 2 3 4 6 9 8 12 18 27 16 24 36 54 81....
- Последовательность Циура – O(n log n)
	1 4 10 23 57 132 301 701 1750 ....
# 34. Сортировка разных типов данных. Индексы, указатели. Сортировка связанных списков.

- Указатель - это адрес ячейки памяти.
- Связанный список - это набор элементов, причем каждый из них является частью узла, который также содержит ссылку. Основное преимущество связанных списков перед массивами заключается в возможности эффективного изменения расположения элементов. За эту гибкость приходится жертвовать скоростью доступа к произвольному элементу списка, поскольку единственный способ получения элемента списка состоит в отслеживании связей от начала списка.
- Индекс - номер элемента.
#### Сортировка разных типов данных
  1) Сортировка чисел
	- **По возрастанию**
	- **По убыванию**
  2) Сортировка строк
	- **Лексикографическая сортировка:** Для строк используется лексикографический порядок, где элементы сравниваются по их лексикографическому порядку (как в словаре). 
	- **Сортировка подсчетом (Counting sort):** Этот метод сортировки подходит для ограниченного предела значений в строках. Он подсчитывает количество каждого символа и затем строит отсортированную строку.
  3) Сортировка обьектов
	- С помощью компаратора - функции сравнения 
#### Сортировка связанных списков
1. Произвольного доступа к элементам сортируемого массива нет, можно двигаться итератором от любого элемента только к соседнему (за O(1)), причём только в одном направлении (вперёд по списку).
2. Модифицировать сам список (перевешивать указатели на следующие элементы) нельзя.
3. Вся информация, которую известно об элементах массива, — это то, что они все образуют линейно упорядоченное множество.
4. Всё, что можно делать, — это сравнивать два элемента массива (за O(1)) и менять их местами (тоже за O(1)).
# 35. Метод распределяющего подсчета

1) Снимаем штаны и бегаем
2) Находим элемент с максимальным ключом - M
3) Создаем вспомогательный массив размером M - 1
4) Заполняем Ai индексы вспомогательного массива количеством элементов с ключом Ai
5) Там еще можно префиксную сумму уебать
6) В целом, это обобщенная сортировка подсчетом.
# 36. Быстрая сортировка

#### Общий механизм сортировки

1) Выбрать элемент из массива – опорный/разделяющий элемент, пиво(т)
2) Разбиение: перераспределение элементов в массиве таким образом, что элементы, меньшие опорного, помещаются перед ним, а большие или равные - после.
3) Рекурсивно применить первые два шага к двум подмассивам слева и справа от опорного элемента. Рекурсия не применяется к массиву, в котором только один элемент или отсутствуют элементы
#### Вопросы???????????????????????
1. Трудоемкость –  
	1. O(n^2) – наихудшее время, маловероятно 
	2. O(n log n) – лучшее, среднее время 
	3. O(n log n) – в среднем обменов

2. Модификация – множество реализаций
    
3. Устойчивость – нет
    
4. Затраты памяти – O(log n) – стек вызовов
    
5. Для каких массивов – все зависит от выбора опорного элемента 
https://youtu.be/Hoixgm4-P4M?si=tCPPHRHoqrnkXbhs
# 37. Сравнительная характеристика выбора опорного элемента в быстрой сортировке

### Первый элемент в качестве опорного
Использование первого элемента в качестве опорного - один из наиболее простых подходов. Однако он может быть неэффективным в ситуациях, когда входные данные уже отсортированы или почти отсортированы. В этом случае быстрая сортировка может превратиться в квадратичный алгоритм.
### Случайный выбор элемента
Случайный выбор опорного элемента уменьшает вероятность худшего случая, когда входные данные уже отсортированы или имеют определенную структуру. Однако этот метод может потребовать дополнительных вычислительных затрат на генерацию случайных чисел.
### Медиана трёх элементов
Этот подход заключается в выборе опорного элемента как медианы из трех: первого, последнего и среднего элементов в массиве. Этот метод предпочтительнее случайного выбора, поскольку он может уменьшить вероятность попадания в худший случай, но может потребовать дополнительных сравнений.
### Метод Хоара (Hoare's method)
Этот метод заключается в выборе опорного элемента как центрального элемента в массиве без дополнительных сравнений. Он обычно хорошо работает в среднем случае, но также может столкнуться с проблемой уже отсортированных данных.
### Метод Ломуто 
выбирает опорный элемент как последний элемент массива. Таким образом, опорный элемент не меняется во время разделения массива на подмассивы. В большинстве практических случаев метод Ломуто обеспечивает хорошие результаты, особенно на случайных или случайно упорядоченных данных.
# 38. Модификации быстрой сортировки. HyperQuicksort, Introsort, PSRS

#### HyperQuicksort

1) Изначально предполагается, что n элементов равномерно распределены по 2^d вершинам гиперкуба так, что каждая вершина содержит N = n/2^d элементов.
2) Сортировка элементов на каждом узле
3) Выбор в качестве опорного элемента чьей-либо медианы
4) Разбиение: перераспределение элементов в массиве таким образом, что элементы, меньшие опорного, помещаются перед ним, а большие или равные - после.
5) Рекурсивно применить первые два шага к двум подмассивам слева и справа от опорного элемента. Рекурсия не применяется к массиву, в котором только один элемент или отсутствуют элементы
6) Сортировка элементов на каждом узле
7) Рекурсивное повторение процедуры
8) Последовательное соединение
O(nlogn)

#### Introsort
Использует быструю сортировку и переключается на пирамидальную когда рекурсии превысит некоторый заранее установленный уровень

#### PSRS

Преимущества по сравнению с быстрой сортировкой:
- сохраняет размер списка более сбалансированным на протяжении всего процесса
- избегает повторных перестановок ключей
1. Сортировка элементов на каждом узле 
2. Выбор на каждом узле ключевых элементов (0, n/P2 , 2n/P2…,(P-1)n/P2)
3. Сбор элементов на одном узле Х, их сортировка. 
4. Выбор на Х P-1 опорных элементов, их рассылка остальным узлам. 
5. Каждый узел делит свои элементы на P частей. Узел i оставляет себе i-ую часть, а j-ую – отправляет узлу j.
6. Каждый узел соединяет полученные части в отсортированный набор. 
7. Последовательное соединение частей
O((nlog(n/p))/p)



# 39. Сортировка слиянием
1) Разделяем массив на подмассивы длиной N/2
2) Рекурсивно повторяем шаг 1)
3) Получаем массивы единичной длины
4) Рекурсивно склеиваем две половинки, сравнивая элементы и выстраивая их в нужном порядке.


# ==*ИГИНАТ ЕСЛИ НАЙДЕШ ЧТО ИСПРАВИТЬ ПИШИ НЕ СТЕСНЯЙСЯ А ЕСЛИ НЕ ДОЧИТАЕШЬ ДО КОНЦА ТО ТЫ ЛОХ*==