# 1. Поразрядная сортировка MSD

## **Суть поразрядной сортировки:**

Алгоритмы поразрядной сортировки рассматривают ключи, как числа, которые представлены в системе счисления с основанием R и работают с отдельными цифрами чисел

### MSD (most significant digit radix sort) - поразрядная сортировка по старшей цифре.

Идея состоит в том, чтобы выполнить следующие шаги для каждой цифры **i**, где значение **i** варьируется от старшей цифры до младшей:
- Храните элементы в разных корзинах в соответствии с их **i-м** разрядом.
- сортируйте каждую ячейку, содержащую более одного элемента.
- ![[Pasted image 20240611215607.png]]

### Проблемы настройки

- **если R принимает чрезмерно большое значение, то большая часть стоимости сортировки приходится на инициализацию и проверку корзин;**
- **если R недостаточно велико, то метод не использует своих потенциальных выгод, что достигается, если разделить исходный файл на максимально возможное число фрагментов.**

### Проблема пустых корзин
При сортировке случайных ключей количество ключей в каждом контейнере (размер подфайлов) после первого прохода в среднем будет равно N/R. На практике ключи могут не быть случайными (например, если ключи — это строки, представляющие собой слова на русском языке, то мы знаем, что лишь немногие из них начинаются с буквы й и совсем нет слов, начинающихся с буквы ъ), так что многие контейнеры окажутся пустыми, а некоторые из непустых контейнеров будут содержать больше ключей, чем остальные.
Пути решения:
- **Эвристика в масштабах корзины (bin-span-heuristics) - 
	- **First Fit (Первое подходящее)**:
	    - Элементы рассматриваются последовательно, и каждый элемент помещается в первый контейнер, который может его вместить во всех измерениях. Этот метод прост в реализации, но не всегда находит оптимальное решение.
	- **Best Fit (Лучшее подходящее)**:
	    - Элементы рассматриваются последовательно, и каждый элемент помещается в контейнер, который оставляет наименьшее свободное пространство после его добавления. Этот метод более вычислительно затратен, но часто дает лучшие результаты по сравнению с First Fit.
	- **Next Fit (Следующее подходящее)**:
	    - Элементы рассматриваются последовательно, и каждый элемент помещается в текущий контейнер, если он подходит, иначе открывается новый контейнер. Этот метод ограничивает количество открытых контейнеров, что может быть полезно в некоторых приложениях.**
- **Разработка более сложной реализации абстрактной операции доступа к конкретным байтам, которая учитывает любые специальные знания о сортируемых строках.**

### Сложность

Пусть значения разрядов меньше b, а количество разрядов — k. При сортировке массива из одинаковых элементов MSD-сортировкой на каждом шаге все элементы будут находится в неубывающей по размеру корзине, а так как цикл идет по всем элементам массива, то получим, что время работы MSD-сортировки оценивается величиной **O(nk)**, причем это время нельзя улучшить. Хорошим случаем для данной сортировки будет массив, при котором на каждом шаге каждая корзина будет делиться на b частей. Как только размер корзины станет равен 1, сортировка перестанет рекурсивно запускаться в этой корзине. Таким образом, асимптотика будет Ω(n logb(n)). Это хорошо тем, что не зависит от числа разрядов.

По памяти O(k), по сути O(n)
### **Условие поразрядной сортировки:**

Основное условие поразрядной сортировки состоит в том, чтобы мы могли разделить ключ, строку, последовательность байтов, которые мы могли бы сравнивать по отдельности, то есть выбирать какие-то определенные части и сравнивать их.

### **Абстракции для работы поразрядной сортировки (с чем она может работать):**

1. Байт - последовательность битов фиксированной длины

2. Строка - последовательность байтов переменной длины

3. Слово - последовательность байтов фиксированной длины

4. Ключ - число в системе счисления с основанием R, цифры которого пронумерованы. (организованы как последовательности байтов)

Все эти абстракции можно разделить на части, которые можно сравнивать

### Частный случай: двоичная поразрядная сортировка:

1. У каждого элемента изначально имеется ключ в двоичной системе счисления, выбираем самый большой разряд, по нему будем сортировать
2. Где единица - вниз, они больше, с 0 вверх, они меньше
3. Получили два блока, далее в каждом блоке берем второй разряд, он будет страшим и уже к каждому из блоков рекурсивно применяем алгоритм сортировки

Суть: Делим на 2 блока, с нулями и единицами в старшем разряде и рекурсивно сортируем по старшему разряду, пока не дойдем до конца ключа

Пример:
![[Pasted image 20240611222130.png]]

Суть: модификация двоичной поразрядной сортировки, только вместо двоичной СС, у нас СС, с основанием R, получается, что наш алгоритм делит на k частей, называемых корзинами и затем в каждой из этих корзин сортирует рекурсивно также разделяя на k частей, пока не дойдет до конца

### Преимущества и недостатки:

- Хорошо параллелится, при этом даже без этого является очень быстрой
- Требует дополнительную память и не всегда работает. Например, на знаковых числах (просто для разных знаков сортировать - неэффективно). Также не очень эффективен, когда много одинаковых элементов
# 2. Трех-путевая поразрядная быстрая сортировка
### Постановка задачи:

Допустим, мы выполняем сортировку строк.

Использовать qsort, который активно сравнивает элементы, выглядит слишком накладным — сравнение строк операция долгая. Да, мы можем написать свой компаратор, который будет несколько эффективнее. Но все же.

Использовать radix, который требует дополнительную память, тоже не слишком мотивирует — строки могут быть большими. Да и большая длина строк, т.е. число разрядов, удручающе сказываются на эффективности.
### Основная идея

**Приспособить быструю сортировку для MSD, используя трехпутевое разделение ключей по старшим байтам с переходом к следующему байту только в среднем подфайле.**

Это комбинация быстрой и поразрядной сортировки.

1. Берем опорный элемент.
2. Разделяем массив на три части, сравнивая элементы с опорным по старшему разряду — на меньшие, равные и большие.
3. В каждой из трех частей процедуру повторяем, начиная с шага №1, до тех пор, не дойдем до пустых частей или частей с 1 элементом.

Только в средней части (т.е. где старший разряд равен старшему разряду опорного элемента) переходим к следующему разряду. В остальных частях операция начинается без изменения «рабочего» разряда.

Пример:
![[Pasted image 20240611222618.png]]

### Сложность:

По сути работает схожим образом, как и быстрая сортировка, по методу “разделяй и властвуй”, поэтому сложность:

**Сложность сортировки — O(n*logn).**

**Дополнительная память — O(1).**

### Преимущества:

- По сравнению с быстрой в том, что нам не нужно выполнять сравнение каждого элемента целиком, что естественно ускоряет процесс
- По сравнению с поразрядной - не требует дополнительной памяти

### Недостатки:

- Более сложна в написании, чем быстрая сортировка
- Хуже параллелится по сравнению с поразрядной сортировкой 
# 3. Поразрядная сортировка LSD
### LSD (least significant digit radix sort) - поразрядная сортировка сначала по младшей цифре.

**Альтернативный метод поразрядной сортировки
› Сортируем по последней букве (используем метод подсчета индексных ключей)
› Сортируем по средней букве


**Работает только в том случае, если доказана устойчивость метода сортировки**

Идея: сортировать элементы не от большего разряда к меньшему, а наоборот

### Алгоритм:

1. Берем последние разряды чисел и поводим сортировку по ним, любой сортировкой, главное, чтобы она была устойчивой(наиболее эффективно, конечно, будет использовать сортировку подсчетом. Именно для нее будет потом рассчитана сложность)
2. Переходим к предпоследнему элементу, также сортируем
3. Производим операции до тех пор, пока не дойдем до конца.

### Почему сортировка должна быть устойчивой?

Если значения разрядов чисел не равны между собой, то элементы могут перемещаться между группами на каждом шаге. Поэтому при реализации LSD sort необходимо использовать стабильную сортировку внутри каждой группы.

Пояснение:

Предположим, что мы используем, неустойчивую сортировку, тогда элементы не сохраняют относительный порядок. Из этого следует, что относительный порядок, который мы задали, никак не будет задействован, из чего следует, что элементы, у которых, все одинаковы разряды, кроме, например, последнего, стоят так, что не удовлетворяют отсортированности, из чего можно сделать вывод, что сортировка не работает

### Сложность

Пусть m — количество разрядов, n — количество объектов, которые нужно отсортировать, T(n) — время работы устойчивой сортировки. Цифровая сортировка выполняет k итераций, на каждой из которой выполняется устойчивая сортировка и не более O(1) других операций. Следовательно время работы цифровой сортировки — O(kT(n)).

Рассмотрим отдельно случай сортировки чисел. Пусть в качестве аргумента сортировке передается массив, в котором содержатся n m-значных чисел, и каждая цифра может принимать значения от 0 до k−1. Тогда цифровая сортировка позволяет отсортировать данный массив за время O(m(n+k)), если устойчивая сортировка имеет время работы O(n+k). Если k небольшое, то оптимально выбирать в качестве устойчивой сортировки сортировку подсчетом.

Если количество разрядов — константа, а k=O(n), то сложность цифровой сортировки составляет O(n), то есть она линейно зависит от количества сортируемых чисел.

### Преимущества и недостатки:

1. Устойчива, довольно быстрая
2. Требует дополнительные затраты памяти и не всегда работает или делает это неэффективно(аналогично MSD)
# 4. Графы и их разновидности
### Граф - совокупность узлов и ребер, соединяющих эти узлы, как структура данных.

### Разновидности графов:

- **Неориентированный/ориентированный**

	G=(V,E) – неориентированный, если из (x,y)∈E следует, что (y,x) также является членом E. В противном случае граф – ориентированный.

- **Взвешенный/Невзвешенный**

	Каждому ребру/вершине взвешенного графа G присваивается числовое значение или вес.

- **Простые/Сложные**
	![[Pasted image 20240611223823.png]]
- **Разреженные/Плотные**
	![[Pasted image 20240611223930.png]]

- **Циклические/Ациклические**
	![[Pasted image 20240611224040.png]]

- **Явные/Неявные**
	![[Pasted image 20240611224112.png]]

- **Вложенные/Топологические**
	![[Pasted image 20240611224133.png]]

- **Помеченные/Непомеченные**
	![[Pasted image 20240611224258.png]]
- **Дерево**
	Дерево - любой связанный граф, не содержащий циклов
	
	Связанный граф - граф, между любой парой вершин которого существует хотя бы 1 путь
# 5. Обход графов, раскраска графов
## Обход графов
### **Обход графа - систематизированное посещение каждой вершины и каждого ребра графа.**

Каждая из вершин находится в одном из состояний: 
- Неоткрытая – первоначальное, нетронутое состояние вершины
- Открытая – вершина обнаружена, но не проверены все ее ребра
- Обработанная – все инцидентные данной вершине ребра были посещены

### Обход в ширину (breadth-first search, BFS)

Идея: берем, изначально, какую-нибудь вершину, помечаем ее. Далее мы берем для этой вершины все вершины, смежные с ней. Заходим в каждую. Если были в ней, то ничего не делаем, если в ней не были, то берем все вершины, смежные с данной. Далее то же самое повторяем, для вершин, которые взяли (т.е. мы каждый раз берем все смежные вершины данной, тем самым каждый раз расширяемся в ширину).

### **Обход в глубину (depth-first search, DFS)**

Идея: выбрать изначально любую вершину графа, и идти по какому-нибудь одному пути, помечая при этом все вершины, в которых были, пока не дойдем до вершины, которую уже посетили, или до вершины, из которой нельзя попасть в другие вершины. (т.е. постоянно спускаемся в глубь). Затем поднимаемся на одну вершину вверх, от той, которая оказалась конечной и повторяем то же самое

Замечание: оба алгоритма являются взаимозаменяемыми, но иногда какой-то из них использовать более выгодно чем другой.

## Раскраска графов

пусть G - некоторый граф, k - натуральное число. тогда раскраской графа называется функция f, которая каждой вершине графа G ставит в соответствие определенные номер {1,…, k}

Раскраска называется правильной, если любым двум смежным вершинам не соответствует одно и то же число, при этом k - минимальное число для этого графа.

_Пояснение:_ раскраска будет правильной, если у нас смежные вершины не раскрашены в один и тот же цвет, при этом мы задействовали минимальное количество цветов.(граф помечен определенным числом, можно визуализировать как граф раскрашен в определенный цвет)
![[Pasted image 20240611224857.png]]
## Двудольная раскраска графов

Задача: раскрасить граф в 2 цвета

Заметим, что если такая раскраска существует, и если зафиксировать цвет одной вершины, то все цвета всех достижимых из неё вершин определяются однозначно: пусть цвет этой вершины белый, тогда все её соседи будут иметь черный цвет, все вершины на расстоянии 2 будут иметь снова белый цвет, все вершины на расстоянии 3 снова черный, и так далее.

Раскрашивать граф можно обходом в глубину. На этот раз наш DFS будет принимать параметром цвет, в который нужно покрасить вершину, и он будет рекурсивно запускаться от всех соседей, крася их в противоположный цвет. По окончании работы алгоритма мы либо обнаружим, что граф не двудолен (мы когда-то посмотрели на две соседние вершины, которым нужно присвоить один и тот же цвет), либо найдём разбиение вершин графа на две доли.
**Пример**
 - Предположим, что в ВУЗе есть N преподавателей. Каждый должен прочитать определенное количество лекций по своему предмету, притом разные преподаватели могут читать свои лекции параллельно, один преподаватель так не может. Каждая лекция пусть занимает 1 час.
- Задача: составить расписание лекций так, чтобы они были прочтены для всех групп за минимальное время (т.е. по сути были прочтены за минимальное количество дней, значит надо сделать так, чтобы было как можно меньше окон)
- Пусть каждая лекция - это вершина графа, смежные вершины те, которые читает один и тот же преподаватель, смежные вершины раскрашиваем в разные цвета. Получаем некоторую раскраску, при этом, если вершины имеют 1 раскраску, то они могут читаться параллельно, значит их можно поставить в расписание на 1 время, если сделаем правильную раскраску, то по сути найдем максимальное количество лекций, которые можно ставить параллельно, при этом получим, что если мы так расставим лекции, то все лекции будут прочтены за минимальное количество часов

подгон от Коли:

[](https://www.youtube.com/watch?v=qoIEi0KA5Xc&t=336s&ab_channel=%D0%A3%D1%87%D0%B8%D0%BC%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%D0%B4%D0%B8%D1%81%D0%BA%D1%80%D0%B5%D1%82%D0%BD%D0%BE%D0%B9%D0%BC%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B8)[https://www.youtube.com/watch?v=qoIEi0KA5Xc&t=336s&ab_channel=Учималгоритмыдискретнойматематики](https://www.youtube.com/watch?v=qoIEi0KA5Xc&t=336s&ab_channel=%D0%A3%D1%87%D0%B8%D0%BC%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%D0%B4%D0%B8%D1%81%D0%BA%D1%80%D0%B5%D1%82%D0%BD%D0%BE%D0%B9%D0%BC%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B8)
# 6. Алгоритм обхода в ширину по сравнению с обходом в глубину
### **Обход в ширину (breadth-first search, BFS)**

**Идея**: берем, изначально, какую-нибудь вершину, помечаем ее. Далее мы берем для этой вершины все вершины, смежные с ней. Заходим в каждую. Если были в ней, то ничего не делаем, если в ней не были, то берем все вершины, смежные с данной. Далее то же самое повторяем, для вершин, которые взяли (т.е. мы каждый раз берем все смежные вершины данной, тем самым каждый раз расширяемся в ширину).

Получается, что при каждой операции мы проверяем, является ли вершина посещенной и, если нет, то собираем все вершины, смежные ей, и даем им самый низкий приоритет. Далее берем еще одну, с нее собираем смежные и даем им самый низкий приоритет, значит приоритет вершин, добавленных до этого надо увеличить. Таким образом, мы приходим к выводу, что для реализации обхода в ширину мы будем использовать структуру данных - очередь, в отличие от обхода в глубину, где мы использовать будем стек.

**Очередь** - обход в ширину. Помещая вершины в очередь типа FIFO, мы исследуем самые старые неисследованные вершины первыми. Таким образом, наше исследование медленно распространяется вширь, начиная от стартовой вершины.

### Итеративный алгоритм

1. Выбираем вершину и кладем ее в очередь
2. Достаем из очереди вершину, помечаем ее как открытую
3. Если вершина изначально не была открытой, то кладем в очередь все вершины, смежные ей
4. Повторяем шаги 2, 3 до тех пор, пока очередь не окажется пустой

### Свойства при обходе в ширину

- _Сохранение порядка, в котором мы открывали вершины графа, и пути позволяет определить минимальный путь от исходной вершины до любой заданной (поскольку у каждой вершины есть только один родитель)._
- Ребра графа, которые не включены в дерево обхода в ширину, также имеют особые свойства. Для неориентированных графов, не попавшие в дерево ребра могут указывать только на вершины на том же уровне, что и родительская вершина, или на вершины, расположенные на уровень ниже. Эти свойства естественно следуют из того факта, что каждое ребро в дереве должно быть кратчайшим путем в графе (есть вершина, если с вершиной, смежной с ней, изначально нет ребра в дереве вершин, то тогда значит, что смежная вершина или на том же уровне с деревом или на 1 уровень ниже).
- Для ориентированных графов ребро (u, v), указывающее в обратном направлении, может существовать в любом случае, когда вершина v расположена ближе к корню, чем вершина u.(у нас есть ребро (u,v). Если v ближе к корню чем u, то ребро (u, v) обязательно может существовать, хотя это не гарантируется)

### Преимущества обхода в ширину, по сравнению с обходом в глубину

- Одним из основных преимуществ обхода в ширину по сравнению с обходом в глубину является то, что он может быть использован для поиска кратчайшего пути в невзвешенном графе. Обход в ширину гарантирует, что кратчайший путь будет найден, если все ребра имеют одинаковый вес. Кроме того, обход в ширину может быть более эффективным при работе с графами, у которых много ребер, но мало уровней.
- Еще одним преимуществом обхода в ширину является то, что он может быть использован для поиска компонент связности в неориентированном графе. Обход в ширину позволяет найти все вершины, которые достижимы из заданной вершины, и таким образом определить компонент связности (максимального связного подграфа).
- Кроме того, обход в ширину может быть более удобным для работы с графами, у которых нет определенной структуры или которые содержат циклы. Обход в ширину позволяет посетить все вершины графа, не застревая в циклах или повторно посещая вершины.
# 7. Алгоритм обхода в глубину по сравнению с обходом в ширину
### **Обход в глубину (depth-first search, DFS)**

**Идея**: выбрать изначально любую вершину графа, и идти по какому-нибудь одному пути, помечая при этом все вершины, в которых были, пока не дойдем до вершины, которую уже посетили, или до вершины, из которой нельзя попасть в другие вершины. (т.е. постоянно спускаемся вглубь). Затем поднимаемся на одну вершину вверх, от той, которая оказалась конечной и повторяем то же самое.

Получается, что мы берем одну вершину, далее, собираем все смежные вершины и даем им максимальный приоритет, переходи-м в одну из них, если не открытая, то снова собираем все смежные вершины и даем им максимальный приоритет. Тем самым приходим к выводу, что нам необходимо использовать стек (или рекурсию, как замену ему)

**Стек** – обход в глубину. Помещая вершины в стек с порядком извлечения LIFO, мы исследуем их, отклоняясь от пути для посещения очередного соседа, и возвращаясь назад, только если оказываемся в окружении ранее открытых вершин. Таким образом, мы в своем исследовании быстро удаляемся от стартовой вершины.

### Итеративный алгоритм

1. Берем вершину и кладем (!!!) ее в стек
2. Вытаскиваем из стека и отмечаем, как открытую
3. Если до этого вершина была закрытой, то кладем в стек все вершины, смежные с ней
4. Повторяем шаги 2-3 до тех пор, пока стек не будет пуст

### Рекурсивный алгоритм

1. берем первую вершину, и запускаем для нее функцию проверки на открытость
2. Если вершина открытая, то завершаем, если нет, то помечаем, как открытую и для каждой вершины, смежной ей запускаем рекурсивно ту же функцию
3. Алгоритм завершится, когда стек рекурсий будет пуст

### Свойства при обходе в глубину

- Посещение предшественника. Если вершина х является предшественником вершины у в дереве обхода в глубину, то временной интервал посещения у должен быть корректно учтен его предшественником
- Количество потомков. Разница во времени выхода и входа для вершины у свидетельствует о количестве потомков этой вершины в дереве обхода в глубину.

**Обход в глубину разбивает ребра на два класса:**

- древесные (tree edges) - используются при открытии новых вершин и закодированы в родительском отношении
- обратные (back edges) - второй конец является предшественником расширяемой вершины

### Преимущество обхода в глубину по сравнению с обходом в ширину

- Один из главных преимуществ обхода в глубину по сравнению с обходом в ширину заключается в том, что он использует меньше памяти. В обходе в ширину необходимо хранить все вершины на текущем уровне, а также все вершины на предыдущих уровнях, что может потребовать значительных объемов памяти при работе с большими графами. В обходе в глубину же используется стек для хранения вершин, что позволяет эффективно использовать память и работать с графами большого размера.
- Кроме того, обход в глубину может быть более эффективен при поиске определенных типов путей или структур в графе, таких как циклы, деревья или компоненты связности. Обход в глубину также может быть более простым и интуитивно понятным для реализации, особенно для начинающих программистов.
# 8. Обход ориентированных графов, топологическая сортировка
## Обход ориентированных графов

Для ориентированных графов обход в глубину и ширину по идее схожи. Итак, при работе с ориентированными графами часто бывает такая ситуация, что граф не является связным, значит до некоторых вершин алгоритм может не дойти, если мы выберем определенную вершину (мы можем выбирать любую вершину для начала работы алгоритма). Значит, чтобы захватить все вершины, необходимо после отработки алгоритма запустить его ещё раз, но в этот раз взять за корень не посещенную вершину.

### Алгоритм:

1. Проверяем посещена ли вершина
2. Если не посещена, то запускаем DFS(BFS) c корнем в этой вершине
3. повторяем шаги 1, 2 до тех пор, пока все вершины не будут посещены

### Применение обхода в глубину для определения вида ребра в ориентированном графе

Древесный граф - это граф, который является связным и не имеет циклов. Древесное ребро - это ребро, которое принадлежит древесному графу и соединяет две вершины в этом графе, при этом не является частью цикла. То есть, если удалить древесное ребро, граф разобьется на два подграфа.

При обходе в глубину неориентированного графа DFS разделяет все ребра на древесные и обратные. При обходе в глубину для ориентированного графа разделение ребер идет на 4 класса:
![[Pasted image 20240611230114.png]]

Также при помощи этого алгоритма можно определять тип ребра в ориентированном графе, это является очень полезным при разработке алгоритмов для работы с ориентированными графами

### Алгоритм определения типа ребра в графе:
![[Pasted image 20240611230135.png]]
**Пояснение**: во время работы алгоритма мы перешли в какую-то вершину, мы ее зафиксировали и передаем в функцию, как вершину y. Вершина x - вершина, которая имеет с y ребро(может, кстати, быть такая ситуация, что ребро есть, а какая-то вершина не найдена, но она будет найдена потом, поэтому в общем случае мы рассматриваем в качестве x не все вершины, а только найденные).

1. Если x - родитель y, то ребро древесное
2. Если вершина была посещена (метка посещения ставится после вызова функции) до этого, при этом не является обработанной (не все вершины, для который она родитель посещены), то ребро обратное
3. Если обработана и при этом время нахождения вершины y больше x, то ребро прямое
4. Если время y меньше времени x, то ребро поперечное

## Топологическая сортировка

Задача: упорядочить вершины вдоль линии таким образом, что все ориентированные ребра направлены слева направо

_Замечание:_ такое упорядочивание ребер невозможно в графе, содержащем ориентированный цикл, так как в таком графе не существует линейного порядка вершин. Любой, бесконтурный ориентированный граф (не содержит обратных ребер) имеет, по крайней мере, одно топологическое упорядочивание

### Зачем нужна?

Важность топологической сортировки состоит в том, что она позволяет упорядочить вершины графа таким образом, что каждую вершину можно обработать перед обработкой ее потомков. Допустим, что ребра представляют управление очередностью таким образом, что ребро (х, у) означает, что работу х нужно выполнить раньше, чем работу у. Тогда любое топологическое упорядочивание определяет правильное календарное расписание. Более того, бесконтурный орграф может содержать несколько таких упорядочиваний.

### Процедура топологической сортировки

- **Если вершина y не открыта, то начинаем обход в глубину из вершины у, прежде чем можем продолжать исследование вершины х**
- **Если вершина у открыта, но не обработана, то ребро (х,у) является обратным ребром, что запрещено в бесконтурном ориентированном графе**
- **Если вершина у обработана, то она помечается соответствующим образом раньше вершины х**


# 9. Обход взвешенных графов. Минимальное остовное дерево. Алгоритм Прима

### Остовное дерево - подмножество ребер Е, которые создают дерево, содержащее все вершины графа V.
![[Pasted image 20240611232350.png]]
Наибольший интерес представляет минимальное остовное дерево - остовные деревья с минимальной суммой весов ребер
Минимальные остовные деревья позволяют решить задачу, в которой требуется соединить множество точек (представляющих города, дома, перекрестки и другие объекты) наименьшим объемом дорожного полотна, проводов, труб и т. п. Любое дерево - это в сущности, наименьший (по количеству ребер) возможный связный граф, в то время как минимальное остовное дерево является наименьшим связным графом по весу ребер.

### Алгоритм Прима (алгоритм построения минимального остовного дерева):

1) Начинаем с указанной вершины
2) Вставляем в остовное дерево одну новую вершину, исходя из “жадного” принципа (из множества рассмотренных ребер к дереву добавляется ребро с наименьшим весом)

_Пояснение:_
1. Берем первую вершину, ищем ребро, исходящее из нее с минимальным весом
2. Добавляем вершину, с котором ребро связывает исходную вершину, к остову
3. Ищем из множества ребер, которые идут из множества вершин, входящих в остов, минимальное ребро, которое соединяет любую вершину остова с вершиной не из остова и добавляем новую вершину
4. повторяем 3 снова, до тех пор, пока не закончатся вершины
![[Pasted image 20240611232509.png]]
![[Pasted image 20240611232707.png]]
![[Pasted image 20240611232730.png]]
![[Pasted image 20240611232913.png]]
### Анализ эффективности алгоритма Прима

Зависит от используемых структур данных Если n – исполняемых циклов; m – просматриваемых ребер в каждом цикле

O($n^2$) – «наивная» реализация O(m + n*lgn) – применение структуры данных в виде кучи с приоритетами (двоичная куча, Фибоначчиева куча)

_Пояснение:_ если использовать “наивную” реализацию, то при поиске минимального ребра мы каждый раз перебираем все ребра, которые нам доступны. При использовании очереди с приоритетам мы просто закидываем в нее все ребра, которые нам доступны, временная сложно закидывания всех ребер будет n*lgn, а получать минимальное ребро мы будем за константу, ну и соответственно добавить все вершин - m операций
# 10. Алгоритма Крускала построения минимального остовного дерева
### опиСАСАНИЕ 

Алгоритм Крускала изначально помещает каждую вершину в своё дерево, а затем постепенно объединяет эти деревья, объединяя на каждой итерации два некоторых дерева некоторым ребром. Перед началом выполнения алгоритма, все рёбра сортируются по весу (в порядке неубывания). Затем начинается процесс объединения: перебираются все рёбра от первого до последнего (в порядке сортировки), и если у текущего ребра его концы принадлежат разным поддеревьям, то эти поддеревья объединяются, а ребро добавляется к ответу. По окончании перебора всех рёбер все вершины окажутся принадлежащими одному поддереву, и ответ найден.
### Алгоритм:

1) Первоначально каждая вершина – отдельный компонент будущего дерева  
2) Последовательно ищем ребро для добавления в расширяющийся лес путем поиска самого легкого среди соединяющих два дерева в лесу  
3) Выполняется проверка на нахождение обеих конечных точек ребра - кандидата в одной и той же связанной компоненте

_Пояснение:_

1. сортируем все ребра графа от наименьшего к наибольшему(это можно сделать обычной сортировкой или просто закинуть их все в очередь с приоритетом)
2. Если вершины, которые данное ребро соединяет: *
    1. оба находятся в одном множестве, то пропускаем ребро
    2. обе вершины не принадлежат ни одному из множеств - соединяем их и образуем новое множество
    3. если вершины принадлежат разным множествам - сливаем множества в одно
    4. если одна вершина принадлежит какому-то множеству, а вторая не принадлежит, то просто добавляем к множеству новую вершину
3. Повторяем шаг 2 до тех пор, пока не закончатся вершины

*проверку всех случаев можно сделать при помощи обхода в глубину или ширину

### Модификация DSU (система непересекающихся множеств):

Эта структура данных предоставляет следующие возможности. Изначально имеется несколько элементов, каждый из которых находится в отдельном (своём собственном) множестве. За одну операцию можно **объединить два каких-либо множества**, а также можно **запросить, в каком множестве** сейчас находится указанный элемент.
Множества элементов мы будем хранить в виде **деревьев**: одно дерево соответствует одному множеству. Корень дерева — это представитель (лидер) множества.
При реализации это означает, что мы заводим массив parent, в котором для каждого элемента мы храним ссылку на его предка в дерева. Для корней деревьев будем считать, что их предок — они сами (т.е. ссылка зацикливается в этом месте).

**объединение:** Чтобы объединить два множества (операция ), мы сначала найдём лидеров множества, в котором находится , и множества, в котором находится . Если лидеры совпали, то ничего не делаем — это значит, что множества и так уже были объединены. В противном случае можно просто указать, что предок вершины  равен  (или наоборот) — тем самым присоединив одно дерево к другому.
Проверка на принадлежность 1 множеству: операции поиска лидера find() проста: мы поднимаемся по предкам от вершины , пока не дойдём до корня, т.е. пока ссылка на предка не ведёт в себя. Эту операцию удобнее реализовать рекурсивно.

### Анализ эффективности алгоритма Крускала

**Зависит от используемых структур данных Если n – вершин; m – ребер O(m lg m) – время упорядочивания ребер (c применением DSU)**
**O(m n) – время исполнения при реализации поиска в ширину или глубину**
![[Pasted image 20240611233054.png]]
![[Pasted image 20240611233119.png]]
![[Pasted image 20240611233615.png]]
![[Pasted image 20240611233646.png]]

# 11. Поиск кратчайшего пути. Алгоритм Дейкстры
### **Путь – последовательность ребер, соединяющих две вершины**

**Задача:** Для заданного взвешенного графа G = (V, E) найти кратчайшие пути (с минимальным весом) из заданной вершины s до всех остальных вершин. Веса всех рёбер неотрицательны.

**Алгоритм:** В ориентированном взвешенном графе, вес рёбер которого неотрицателен w: E→ℝ, алгоритм Дейкстры находит длины кратчайших путей из заданной вершины s до всех остальных. В алгоритме поддерживается множество вершин U, для которых уже вычислены длины кратчайших путей до них из s. На каждой итерации выбирается вершина u∉U, которой не соответствует минимальная оценка кратчайшего пути. Вершина u добавляется в множество U и производится релаксация всех исходящих из неё рёбер.

_Пояснение:_

Изначально у нас есть 2 точки, надо попасть из одной в другую. Пусть расстояние от начальной вершины, до каждой вершины графа $+\infty$

1. выбираем все ребра, которые соединяют текущую вершину и смежные. Расстояние от начальной вершины до данной равно L. Пусть расстояние от текущей до смежной равно $m_i$, а расстояние от начальной вершины до вершин, смежных с L - $l_i$.
2. Если мы рассматриваем вершину L, то мы уже точно нашли кратчайший путь от начальной вершины до этой и он равен L. для каждой вершины сравниваем L+$m_i$ и $l_i$
3. Если $L+m_i<l_i$, то обновляем минимальное расстояние от начальной вершины до данной смежной вершины
4. Далее либо используем BFS и кидаем все вершины в очередь, либо DFS(обойти все равно придется весь граф, поэтому разница, что использовать - нет)
5. Повторяем 1-4 до тех пор, пока не обойдем весь граф и не дойдем до нужной вершины

_Замечание:_ Алгоритм Дейкстры работает правильно только на графах, в которых нет ребер с отрицательным весом. Дело в том, что при построении пути может встретиться ребро с отрицательным весом настолько большим по модулю, что оно полностью изменит оптимальный путь от вершины s к какой-то другой вершине, которая уже включена в дерево. Образно говоря, самым выгодным путем к соседу по лестничной клетке может оказаться путь через банк на другом конце города, если этот банк выдает за каждое посещение достаточно большое вознаграждение, делающее такой маршрут выгодным.
### Эффективность алгоритма Дейкстры
![[Pasted image 20240611233820.png]]![[Pasted image 20240611234238.png]]



# 12. Вычислительная геометрия. Элементарные задачи вычислительной геометрии
### Вычислительная геометрия — раздел информатики, в котором рассматриваются алгоритмы для решения геометрических задач.

### Области применения вычислительной геометрии:

- Компьютерная графика
    - пересечения примитивов
    - удаление невидимых поверхностей, освещение
- Робототехника
    - кинематика
- Геоинформационные системы
    - интерполяция, хранение данных, работа со слоями
- CAD/CAM/CAE
    - CAD (computer-aided design) - проектирование с помощью ЭВМ
    - CAM (computer-aided manufacturing) - компьютерная поддержка производства
    - CAE (computer-aided engineering) - класс продуктов для компьютерной поддержки расчетов и инженерного анализа
- и другие ….

### Элементарные задачи вычислительной геометрии

- Находится ли точка p на отрезке? Если не находится, то с какой стороны?
- Пересекаются ли два отрезка $l_1$ и $l_2$?
- Триангуляции треугольников
- Поиск ближайшей точки
- Выявление пересечений

### Что важно в задачах вычислительной геометрии

- Понимание геометрических свойств задачи
- Правильное применение алгоритмов и структур данных

### Примеры задач вычислительной геометрии

- Пример 1
Представьте, что вы идете по территории университетского городка (кампуса) и внезапно вспоминаете, что должны срочно позвонить. На территории много телефонных будок и, естественно, вам нужна ближайшая. Но какая из них ближайшая? Хорошо бы иметь карту, на которой можно найти ближайшую будку, в какой бы точке кампуса вы ни находились. На такой карте было бы показано разбиение кампуса на области и для каждой из них – ближайшая телефонная будка. Как выглядят такие области? И как их построить?

- Пример 2
Допустим, вы нашли ближайшую телефонную будку. С картой кампуса в руках вы, надо полагать, без особого труда найдете достаточно короткий путь в обход стен и других препятствий. Но вот запрограммировать робота для решения той же задачи будет посложнее. И в этом случае задача имеет геометрическую природу: при заданном наборе геометрических препятствий найти кратчайший путь между двумя точками, избегающий столкновений с препятствиями.

- Пример 3
Допустим, что у вас не одна карта, а две: на одной нанесены различные здания, в т. ч. и телефонные будки, а на другой – дороги на территории кампуса. Чтобы спланировать маршрут к будке, мы должны наложить карты друг на друга, т. е. объединить содержащуюся в них информацию.

# 13. Базовые алгоритмы вычислительной геометрии. Проблемы реализации

### **Геометрическая вырожденность – частные случаи, требующие специальных подходов.**

Решения:

1. Игнорирование
    Пренебрежение вырожденными случаями, преимущество в том, что нет необходимости совершенствовать и усложнять алгоритм, но могу возникать проблемы с правильностью результатов
    
2. Подделка невырожденности
    Немного подкорректировать случай так, чтобы он оказался вырожденным, преимущества и недостатки аналогичны игнорированию
    
3. Обработка вырожденности
    Создавать определенные условия работы алгоритмов, для обработки вырожденных случаев, преимущества в том, что в таком случае ответ будет наиболее правильным, но может сильно усложниться алгоритм.
    

### **Численная неустойчивость – случаи, когда применение арифметических операций может привести к проблемам переполнения или потери точности.**

Решения:

1. Использование целочисленных арифметических операций
2. Использование действительных чисел двойной точности
3. Использование арифметических операций произвольной точности

## Базовые алгоритмы

### 1. Вычисление площади треугольника

![[Pasted image 20240611234740.png]]
### Почему работает?

Площадь треугольника $(a_x,a_y), (b_x, b_y), (c_x, c_y)$ - координаты вершин треугольника на плоскости. Площадь треугольника, построенного на векторах можно вычислить через определитель, площадь треугольника = $\frac{1}{2}$ площади параллелограмма

Стороны на которых построен параллелограмм: $(a_x - b_x,a_y - b_y), (b_x - c_x, b_y - c_y)$

$$ \begin{vmatrix} a_x - b_x& b_x - c_x\\ a_y - b_y& b_y - c_y\end{vmatrix} = (a_x - b_x)(b_y - c_y) - (b_x - c_x)(a_y - b_y) = \begin{vmatrix} a_x & a_y & 1\\ b_x & b_y & 1 \\ c_x & с_y & 1\end{vmatrix} $$

Объем треугольной пирамиды $(a_x,a_y), (b_x, b_y), (c_x, c_y), (d_x, d_y)$ - координаты вершин пирамиды (это второй определитель)

### 2. Выяснение местоположения точки

![[Pasted image 20240611234805.png]]
_Пояснение:_ если определитель больше 0, то площадь треугольника положительно ориентирована, значит минимальный поворот от одного вектора к другому против часовой стрелки, значит точка с - выше прямой, с < 0 аналогично, если 0, то координаты точек пропорциональны, значит лежат на 1 прямой

### 3. Проверка нахождения точки внутри круга
![[Pasted image 20240611234826.png]]

# 14. Алгоритмы вычисления выпуклой оболочки

### **1. В**ыпуклая оболочка

Множество S на плоскости называется выпуклым, если для любых двух точек p,q∈S весь отрезок pq принадлежит S.

**_Выпуклая оболочка_ – конечное множество Р точек однозначно определенного многоугольника, вершинами которого являются точки, принадлежащие Р, и который содержит все точки Р.**
![[Pasted image 20240611235006.png]]
### Вычисление выпуклой оболочки $O(n^3)$

![[Pasted image 20240611235036.png]]

_Пояснение:_

берем 2 точки, через них проходит ровно 1 прямая, если существует точка, которая находится левее данной прямой, то, очевидно, что данный отрезок не будет принадлежать выпуклой оболочке, значит мы его выбрасываем. Берем следующие 2 точки, и так далее, пока прямые не закончатся. Получим множество отрезков, которые и составляют выпуклую оболочку

### Convex Hull ($nlog_2n)$

![[Pasted image 20240611235112.png]]

Идея: Построить сначала нижнюю оболочку, затем верхнюю и соединить их, получив необходимую нам выпуклую оболочку

Псевдокод инкрементного алгоритма:

![[Pasted image 20240611235245.png]]
_Пояснение:_

1. сортируем точки по координате x
2. начинаем строить верхнюю часть
3. добавляем первые 2 точки в множество выпуклой оболочки
4. обозначим последние 2 добавленные точки p и q
5. берем следующую точку m
6. считаем определитель с точками p, q, m
7. если > 0, то m лежит выше прямой, проходящей через точки p и q, тогда удаляем точку q и за p и q снова берем последние точки принадлежащие множеству
8. Повторяем шаги 6-7 до тех пор, пока в множестве не останется 2 точки или когда определитель не будет ≤ 0
9. добавляем в множество точку m
10. повторяем шаги 3-9 до тех пор, пока не закончатся точки
11. Аналогично, с учетом знака строим нижнюю оболочку
12. объединяем оболочки

### Проблемы при построении выпуклой оболочки

- С каким количеством измерений мы имеем дело?

сложность с увеличением размерности

- Данные представлены в виде вершин или полупространств?

задача поиска пересечения набора n полупространств в d-мерном пространстве двойственна поиску выпуклых оболочек из n точек в d-мерном пространстве

- Сколько точек может содержать оболочка?

удаление точек заведомо находящихся внутри

- Как выяснить форму данного набора точек?

потеря подробности O/G, альфа-очертания

### Теорема выпуклой оболочки. **Выпуклую оболочку множества n точек на плоскости можно вычислить за время О(n logn).**

Такая оценка возникает, когда используется алгоритм "разделяй и властвуй", основанный на рекурсивном делении множества точек на полуплоскости. В этом случае выпуклая оболочка рассматривается как объединение выпуклых многогранников, полученных рекурсивным делением исходного множества. Каждый этап рекурсии занимает O(n), а общее количество таких этапов не превосходит O(log n), поскольку максимальное количество полуплоскостей, на которые может быть разбита выпуклая оболочка, равно n.

# 15. Алгоритмы выявления пересечений


![[Untitled-7.png]]
### Проблемы в задаче выявления пересечений:

- Вычисление местонахождения пересечения или сам его факт ?
- Выявление пересечения прямых или отрезков ?
- Ожидаемое количество пересечений ?
- Видна ли точка x из точки y ?
- Являются ли пересекающиеся объекты выпуклыми ?
- Выполняется ли многократный поиск пересечений с одними и теми же основными объектами ?

### Алгоритм заметания плоскости

![[Untitled-6.png]]
Идея алгоритмов этого типа заключается в представлении себе воображаемой прямой (чаще вертикальной), которая движется по плоскости, останавливаясь в некоторых точках. Геометрические операции ограничены геометрическими объектами, которые или пересекаются, или примыкают к выметающей прямой, а полное решение доступно, когда прямая пройдёт через все объекты.

_Пояснение идеи:_ прямая движется слева направо, если встречает начало или конец отрезка, а также точку пересечения, то обрабатывает это событие, естественно, что мы не можем использовать непрерывную величину, значит будем прыгать по этим трем событиям

Объяснение алгоритма (первые 30 минут): [https://youtu.be/sINIi2mwYls](https://youtu.be/sINIi2mwYls) (новосибирск сила)

Подробное описание алгоритма (со страницы 27): [dmitr (ipo.spb.ru)](http://ipo.spb.ru/journal/content/896/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B%20%D0%B2%D1%8B%D1%87%D0%B8%D1%81%D0%BB%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%BE%D0%B9%20%D0%B3%D0%B5%D0%BE%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D0%B8.%20%D0%9F%D0%B5%D1%80%D0%B5%D1%81%D0%B5%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D0%BE%D1%82%D1%80%D0%B5%D0%B7%D0%BA%D0%BE%D0%B2:%20%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%20%D0%B7%D0%B0%D0%BC%D0%B5%D1%82%D0%B0%D0%BD%D0%B8%D1%8F%20%D0%BF%D0%BB%D0%BE%D1%81%D0%BA%D0%BE%D1%81%D1%82%D0%B8..pdf)

### Псевдокод(если не понимаешь, посмотри видео)

![[Untitled-5.png]]
![[Untitled-4.png]]
### Структуры данных

- Очередь событий (приоритетная очередь) - очередь, упорядоченная по x(y) координате, всех возможных будущих событий: вставок, удалений, пересечений.
- Структура состояний - динамическая структура, используется для доступа к соседям данного отрезка s, чтобы можно было проверить, пересекаются ли они с s.

![[Untitled-3.png]]
![[Untitled-2.png]]
![[Untitled.png]]
Время работы: O(n*log n+I*logn)